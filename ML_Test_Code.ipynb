{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3633e502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924f1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload files from postgres table here & read files \n",
    "\n",
    "file_path = 'example_file'\n",
    "example_df = pd.read_csv(file_path)\n",
    "example_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e22f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d71d52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform any data cleaning here with data \n",
    "     #check for null values and drop = for column in df.columns:\n",
    "    print(f\"Columns {column} has {example.df[column].isnull().sum()} null values\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4030f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for duplicates \n",
    "#print(f\"Duplicate entries : {example_df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2396dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit the encoder and produce encoded DataFrame\n",
    "encode_df = pd.DataFrame(enc.fit_transform(example_df.columns.values.reshape(-1,1)))\n",
    "\n",
    "# Rename encoded columns\n",
    "encode_df.columns = enc.get_feature_names(['columns'])\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa6e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale any data using standard scaler \n",
    "\n",
    "# Create the StandardScaler instance\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e788f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaled_data = scaler.transform(encode_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f90fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with the scaled data\n",
    "transformed_scaled_data = pd.DataFrame(scaled_data, columns=encode_df.columns)\n",
    "transformed_scaled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b492a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#use k means method and elbow curve to find best K \n",
    "\n",
    "inertia = []\n",
    "k = list(range(1, 11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8bc983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking for the best K\n",
    "for i in k:\n",
    "    km = KMeans(n_clusters=i, random_state=0)\n",
    "    km.fit(df_iris)\n",
    "    inertia.append(km.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e53dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a DataFrame to plot the Elbow Curve using hvPlot\n",
    "elbow_data = {\"k\": k, \"inertia\": inertia}\n",
    "df_elbow = pd.DataFrame(transformed_scaled_data)\n",
    "df_elbow.hvplot.line(x=\"k\", y=\"inertia\", title=\"Elbow Curve\", xticks=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf15b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(k, data):\n",
    "    # Create a copy of the DataFrame\n",
    "    data = data.copy()\n",
    "\n",
    "    # Initialize the K-Means model\n",
    "    model = KMeans(n_clusters=k, random_state=0)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(data)\n",
    "\n",
    "    # Predict clusters\n",
    "    predictions = model.predict(data)\n",
    "\n",
    "    # Create return DataFrame with predicted clusters\n",
    "    data[\"class\"] = model.labels_\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a846fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_clusters = get_clusters(5, df)\n",
    "\n",
    "ex_clusters.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot data on scatter plot to visualize \n",
    "\n",
    "ex_clusters.hvplot.scatter(x=\"Household_Income\", y=\"Number of EV Registrations\", by=\"class\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
